{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VpdgYduvudVM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Date Time</th>\n",
       "      <th>URL</th>\n",
       "      <th>Tweet Text</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>h</th>\n",
       "      <th>Replied Tweet User ID</th>\n",
       "      <th>Replied Tweet User name</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Favorite Count</th>\n",
       "      <th>Favorited</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-02 00:00:00</td>\n",
       "      <td>06:48:15</td>\n",
       "      <td>Tue Mar 02 06:48:15 +0000 2021</td>\n",
       "      <td>https://twitter.com/AlArabiya/status/136664148...</td>\n",
       "      <td>سي إن إن تستعد إدارة الرئيس بايدن لفرض عقوبات ...</td>\n",
       "      <td>سي ان ان تستعد اداره الرئيس بايدن لفرض عقوبات ...</td>\n",
       "      <td>AlArabiya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-22 00:00:00</td>\n",
       "      <td>19:50:00</td>\n",
       "      <td>Mon Feb 22 19:50:00 +0000 2021</td>\n",
       "      <td>https://twitter.com/skynewsarabia/status/13639...</td>\n",
       "      <td>حكم يتصدى لكرة في طريقها لمرمى في لقطة كوميدية...</td>\n",
       "      <td>حكم يتصدي لكره في طريقها لمرمي في لقطه كوميديه...</td>\n",
       "      <td>skynewsarabia</td>\n",
       "      <td>Abu Dhabi, UAE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-25 00:00:00</td>\n",
       "      <td>16:21:48</td>\n",
       "      <td>Thu Feb 25 16:21:48 +0000 2021</td>\n",
       "      <td>https://twitter.com/AlArabiya/status/136497388...</td>\n",
       "      <td>تابعونا على العربية عبر برنامج بانوراما ال بتو...</td>\n",
       "      <td>تابعونا علي العربيه عبر برنامج بانوراما ال بتو...</td>\n",
       "      <td>AlArabiya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-13 00:00:00</td>\n",
       "      <td>23:59:16</td>\n",
       "      <td>Sat Feb 13 23:59:16 +0000 2021</td>\n",
       "      <td>https://twitter.com/AlArabiya/status/136074035...</td>\n",
       "      <td>خبير بفريق التحقيق في منظمة الصحة العالمية بكي...</td>\n",
       "      <td>خبير بفريق التحقيق في منظمه الصحه العالميه بكي...</td>\n",
       "      <td>AlArabiya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "      <td>Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>12:42:15</td>\n",
       "      <td>Mon Mar 01 12:42:15 +0000 2021</td>\n",
       "      <td>https://twitter.com/AlArabiya/status/136636818...</td>\n",
       "      <td>بالوثائق تعرف على أهم الاتفاقيات التاريخية لتر...</td>\n",
       "      <td>بالوثائق تعرف علي اهم الاتفاقيات التاريخيه لتر...</td>\n",
       "      <td>AlArabiya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>13:48:03</td>\n",
       "      <td>2021-03-07 00:00:00</td>\n",
       "      <td>2021-03-07 13:48:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>شاهد قبل الحذف غيد بلاير</td>\n",
       "      <td>شاهد قبل الحذف غيد بلاير</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>2020-12-10 00:00:00</td>\n",
       "      <td>05:21:29</td>\n",
       "      <td>Wed Feb 10 05:21:29 +0000 2021</td>\n",
       "      <td>https://twitter.com/skynewsarabia/status/13593...</td>\n",
       "      <td>هل يجب إصدار تعليمات صحية جديدة تعلق بمن تلقوا...</td>\n",
       "      <td>هل يجب اصدار تعليمات صحيه جديده تعلق بمن تلقوا...</td>\n",
       "      <td>skynewsarabia</td>\n",
       "      <td>Abu Dhabi, UAE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>2021-02-25 00:00:00</td>\n",
       "      <td>17:19:16</td>\n",
       "      <td>Thu Feb 25 17:19:16 +0000 2021</td>\n",
       "      <td>https://twitter.com/AlArabiya/status/136498834...</td>\n",
       "      <td>المتحدث باسم الاتحاد الأوروبي بيتر ستانو ل الع...</td>\n",
       "      <td>المتحدث باسم الاتحاد الاوروبي بيتر ستانو ل الع...</td>\n",
       "      <td>AlArabiya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>12:36:39</td>\n",
       "      <td>2021-03-10 00:00:00</td>\n",
       "      <td>2021-03-10 12:36:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>شاركنا الحل الصحيح لفرصة فوز كوبون من صيدلية ا...</td>\n",
       "      <td>شاركنا الحل الصحيح لفرصه فوز كوبون من صيدليه ا...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>2021-02-15 00:00:00</td>\n",
       "      <td>09:39:13</td>\n",
       "      <td>Mon Feb 15 09:39:13 +0000 2021</td>\n",
       "      <td>https://twitter.com/AlArabiya/status/136124869...</td>\n",
       "      <td>الصحفي عامر تمام الصين والولايات المتحدة تعامل...</td>\n",
       "      <td>الصحفي عامر تمام الصين والولايات المتحده تعامل...</td>\n",
       "      <td>AlArabiya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>Ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date                 Time  \\\n",
       "0      2021-03-02 00:00:00             06:48:15   \n",
       "1      2020-12-22 00:00:00             19:50:00   \n",
       "2      2021-02-25 00:00:00             16:21:48   \n",
       "3      2021-02-13 00:00:00             23:59:16   \n",
       "4      2021-03-01 00:00:00             12:42:15   \n",
       "...                    ...                  ...   \n",
       "13235             13:48:03  2021-03-07 00:00:00   \n",
       "13236  2020-12-10 00:00:00             05:21:29   \n",
       "13237  2021-02-25 00:00:00             17:19:16   \n",
       "13238             12:36:39  2021-03-10 00:00:00   \n",
       "13239  2021-02-15 00:00:00             09:39:13   \n",
       "\n",
       "                            Date Time  \\\n",
       "0      Tue Mar 02 06:48:15 +0000 2021   \n",
       "1      Mon Feb 22 19:50:00 +0000 2021   \n",
       "2      Thu Feb 25 16:21:48 +0000 2021   \n",
       "3      Sat Feb 13 23:59:16 +0000 2021   \n",
       "4      Mon Mar 01 12:42:15 +0000 2021   \n",
       "...                               ...   \n",
       "13235             2021-03-07 13:48:03   \n",
       "13236  Wed Feb 10 05:21:29 +0000 2021   \n",
       "13237  Thu Feb 25 17:19:16 +0000 2021   \n",
       "13238             2021-03-10 12:36:39   \n",
       "13239  Mon Feb 15 09:39:13 +0000 2021   \n",
       "\n",
       "                                                     URL  \\\n",
       "0      https://twitter.com/AlArabiya/status/136664148...   \n",
       "1      https://twitter.com/skynewsarabia/status/13639...   \n",
       "2      https://twitter.com/AlArabiya/status/136497388...   \n",
       "3      https://twitter.com/AlArabiya/status/136074035...   \n",
       "4      https://twitter.com/AlArabiya/status/136636818...   \n",
       "...                                                  ...   \n",
       "13235                                                NaN   \n",
       "13236  https://twitter.com/skynewsarabia/status/13593...   \n",
       "13237  https://twitter.com/AlArabiya/status/136498834...   \n",
       "13238                                                NaN   \n",
       "13239  https://twitter.com/AlArabiya/status/136124869...   \n",
       "\n",
       "                                              Tweet Text  \\\n",
       "0      سي إن إن تستعد إدارة الرئيس بايدن لفرض عقوبات ...   \n",
       "1      حكم يتصدى لكرة في طريقها لمرمى في لقطة كوميدية...   \n",
       "2      تابعونا على العربية عبر برنامج بانوراما ال بتو...   \n",
       "3      خبير بفريق التحقيق في منظمة الصحة العالمية بكي...   \n",
       "4      بالوثائق تعرف على أهم الاتفاقيات التاريخية لتر...   \n",
       "...                                                  ...   \n",
       "13235                           شاهد قبل الحذف غيد بلاير   \n",
       "13236  هل يجب إصدار تعليمات صحية جديدة تعلق بمن تلقوا...   \n",
       "13237  المتحدث باسم الاتحاد الأوروبي بيتر ستانو ل الع...   \n",
       "13238  شاركنا الحل الصحيح لفرصة فوز كوبون من صيدلية ا...   \n",
       "13239  الصحفي عامر تمام الصين والولايات المتحدة تعامل...   \n",
       "\n",
       "                                            Cleaned Text      User Name  \\\n",
       "0      سي ان ان تستعد اداره الرئيس بايدن لفرض عقوبات ...      AlArabiya   \n",
       "1      حكم يتصدي لكره في طريقها لمرمي في لقطه كوميديه...  skynewsarabia   \n",
       "2      تابعونا علي العربيه عبر برنامج بانوراما ال بتو...      AlArabiya   \n",
       "3      خبير بفريق التحقيق في منظمه الصحه العالميه بكي...      AlArabiya   \n",
       "4      بالوثائق تعرف علي اهم الاتفاقيات التاريخيه لتر...      AlArabiya   \n",
       "...                                                  ...            ...   \n",
       "13235                           شاهد قبل الحذف غيد بلاير            NaN   \n",
       "13236  هل يجب اصدار تعليمات صحيه جديده تعلق بمن تلقوا...  skynewsarabia   \n",
       "13237  المتحدث باسم الاتحاد الاوروبي بيتر ستانو ل الع...      AlArabiya   \n",
       "13238  شاركنا الحل الصحيح لفرصه فوز كوبون من صيدليه ا...            NaN   \n",
       "13239  الصحفي عامر تمام الصين والولايات المتحده تعامل...      AlArabiya   \n",
       "\n",
       "             Location  h   Replied Tweet User ID Replied Tweet User name  \\\n",
       "0                 NaN NaN                    NaN                     NaN   \n",
       "1      Abu Dhabi, UAE NaN                    NaN                     NaN   \n",
       "2                 NaN NaN                    NaN                     NaN   \n",
       "3                 NaN NaN                    NaN                     NaN   \n",
       "4                 NaN NaN                    NaN                     NaN   \n",
       "...               ...  ..                    ...                     ...   \n",
       "13235             NaN NaN                    NaN                     NaN   \n",
       "13236  Abu Dhabi, UAE NaN                    NaN                     NaN   \n",
       "13237             NaN NaN                    NaN                     NaN   \n",
       "13238             NaN NaN                    NaN                     NaN   \n",
       "13239             NaN NaN                    NaN                     NaN   \n",
       "\n",
       "       Coordinates  Retweet Count  Favorite Count Favorited Label  \n",
       "0              NaN            4.0              20     False   Ham  \n",
       "1              NaN            5.0              36     False   Ham  \n",
       "2              NaN            4.0              19     False   Ham  \n",
       "3              NaN            7.0              38     False   Ham  \n",
       "4              NaN            4.0              16     False   Ham  \n",
       "...            ...            ...             ...       ...   ...  \n",
       "13235          NaN            0.0               1     False  Spam  \n",
       "13236          NaN            7.0              22     False   Ham  \n",
       "13237          NaN            3.0              11     False   Ham  \n",
       "13238          NaN          560.0               0     False  Spam  \n",
       "13239          NaN            3.0              11     False   Ham  \n",
       "\n",
       "[13240 rows x 16 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd \n",
    "data = pd.read_excel('C:/Users/DELL/Downloads/Dataset of Arabic Spam and Ham Tweets.xlsx')\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2IsN62BW39iF",
    "outputId": "43fdd019-1a87-47ef-ea52-5c383f7242cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80RJZB8L0Gqi",
    "outputId": "fd7c4106-911d-4189-f7d4-31f5d509426d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipTvud0R9GnV",
    "outputId": "88deeb04-a0b3-4537-8c33-0e3b949d6ccf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = LabelEncoder().fit_transform(data['Label'])\n",
    "#y = LabelEncoder().fit_transform(df['Sentiment'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQeVB-2R3AQv",
    "outputId": "d4c85d33-e547-448a-fa31-1c922dbfebcc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Abdelkareem/arabic_tweets_spam_or_ham\")\n",
    "bert = TFAutoModelForSequenceClassification.from_pretrained(\"Abdelkareem/arabic_tweets_spam_or_ham\",from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "K5HVqkFidPLG"
   },
   "outputs": [],
   "source": [
    "data=data['Cleaned Text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WA82BIHMkayT"
   },
   "outputs": [],
   "source": [
    "max_len=91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "L-5rdkPf9MqP"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "csrWh6M_iY1M"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.dropna()\n",
    "X_test = X_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UzuhB032kHWJ"
   },
   "outputs": [],
   "source": [
    "X_train = list(X_train)\n",
    "X_test = list(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "X1fjJNLsguO5"
   },
   "outputs": [],
   "source": [
    "x_train = tokenizer(\n",
    "    text=X_train,\n",
    "    add_special_tokens=True,\n",
    "    max_length = max_len,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hfwuUr4AkWAq"
   },
   "outputs": [],
   "source": [
    "x_test = tokenizer(\n",
    "    text=X_test,\n",
    "    add_special_tokens=True,\n",
    "    max_length = 86,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "2Pp5JPufkmBA"
   },
   "outputs": [],
   "source": [
    "input_ids = x_train['input_ids']\n",
    "attention_mask = x_train['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wolMLA3EksZA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense,LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "JgO4GwGEyYoq"
   },
   "outputs": [],
   "source": [
    "input_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "bert.trainable=False\n",
    "embeddings = bert(input_ids,attention_mask = input_mask)[0]\n",
    "out = Dense(128, activation='relu')(embeddings)\n",
    "out = tf.keras.layers.Dropout(0.1)(out)\n",
    "out = Dense(64,activation = 'relu')(out)\n",
    "y = Dense(1,activation = 'softmax')(out)\n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cf3OdXnB21qm",
    "outputId": "a9f12673-b607-4c9c-ab09-dc6872c44a1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 91)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 91)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_for_sequence_classific  TFSequenceClassifie  135194882  ['input_ids[0][0]',              \n",
      " ation (TFBertForSequenceClassi  rOutput(loss=None,               'attention_mask[0][0]']         \n",
      " fication)                      logits=(None, 2),                                                 \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None)                                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          384         ['tf_bert_for_sequence_classifica\n",
      "                                                                 tion[0][0]']                     \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            65          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 135,203,587\n",
      "Trainable params: 135,203,587\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Fm5miOwM3I4n"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "nesterov = True\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum, nesterov=nesterov)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9ptyGXhBzdV",
    "outputId": "3a260cd2-c9d6-4ce2-ec9b-fce476987f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10592,)\n",
      "(2,)\n",
      "(10591, 91)\n"
     ]
    }
   ],
   "source": [
    "yyy=np.array(Y_train)\n",
    "print(yyy.shape)\n",
    "zzz=np.array(x_train)\n",
    "print(zzz.shape)\n",
    "print(x_train['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yNz4LJ87tqn",
    "outputId": "f9757671-de26-491f-9d9d-677a7117b81c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10591,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming y_train is a Python list\n",
    "Y_train = np.array(Y_train)\n",
    "Y_train = np.delete(Y_train, 1, axis=0)\n",
    "\n",
    "# Verify the shape of the modified y_train\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "1tKT_7QX3tVQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 3369s 40s/step - loss: 0.3427 - accuracy: 0.1479\n"
     ]
    }
   ],
   "source": [
    "  train_history = model.fit(\n",
    "      x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n",
    "      y = Y_train,\n",
    "      \n",
    "    epochs=1,\n",
    "    batch_size = 128\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForMaskedLM: ['cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing TFBertForMaskedLM from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForMaskedLM from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, TFAutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
    "asa = TFAutoModelForMaskedLM.from_pretrained(\"asafaya/bert-base-arabic\",from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer(\n",
    "    text=X_train,\n",
    "    add_special_tokens=True,\n",
    "    max_length = max_len,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tokenizer(\n",
    "    text=X_test,\n",
    "    add_special_tokens=True,\n",
    "    max_length = 86,\n",
    "     return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True,\n",
    "    truncation=True,\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = x_train['input_ids']\n",
    "attention_mask = x_train['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "asa.trainable=False\n",
    "\n",
    "embeddings = asa(input_ids,attention_mask = input_mask)[0]\n",
    "\n",
    "out = Dense(128, activation='relu')(embeddings)\n",
    "out = tf.keras.layers.Dropout(0.1)(out)\n",
    "out = Dense(64,activation = 'relu')(out)\n",
    "y = Dense(1,activation = 'softmax')(out)\n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.asarray(Y_train).astype('float32').reshape((-1,1))\n",
    "Y_test = np.asarray(Y_test).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10591, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming y_train is a Python list\n",
    "Y_train = np.array(Y_train)\n",
    "Y_train = np.delete(Y_train, 1, axis=0)\n",
    "\n",
    "# Verify the shape of the modified y_train\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 4317s 52s/step - loss: 13.0161 - accuracy: 0.1464\n"
     ]
    }
   ],
   "source": [
    "  train_history = model.fit(\n",
    "      x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n",
    "      y = Y_train,\n",
    "      \n",
    "    epochs=1,\n",
    "    batch_size = 128\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
